{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qC8PJJeTHpQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2393a5-4e13-43a4-b302-dd5ce1a8e441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# Python string -> Sequence of Unicode code points.\n",
        "# See: https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str\n",
        "text = \"ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡ºâ€ŒğŸ‡³â€ŒğŸ‡®â€ŒğŸ‡¨â€ŒğŸ‡´â€ŒğŸ‡©â€ŒğŸ‡ª! ğŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.\"\n",
        "print(type(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# str.encode() converts a given string to bytes based on the passed encoding.\n",
        "# Default encoding is `utf-8`. The inverse of this is bytes.decode('utf-8')\n",
        "tokens = text.encode('utf-8')\n",
        "type(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBrLyDzJIC3v",
        "outputId": "a84ab657-8031-4d2c-d1ee-b8a62abe8a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python bytes can only contain ASCII characters, so parsing the string directly\n",
        "# as bytes will create an error. Hence the workaround from string to bytes.\n",
        "#\n",
        "# byte_text = b\"ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡ºâ€ŒğŸ‡³â€ŒğŸ‡®â€ŒğŸ‡¨â€ŒğŸ‡´â€ŒğŸ‡©â€ŒğŸ‡ª! ğŸ˜„\"\n",
        "\n",
        "#  File \"<ipython-input-4-dd9153d8f4e5>\", line 4\n",
        "#    byte_text = b\"ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡ºâ€ŒğŸ‡³â€ŒğŸ‡®â€ŒğŸ‡¨â€ŒğŸ‡´â€ŒğŸ‡©â€ŒğŸ‡ª! ğŸ˜„\"\n",
        "#                ^\n",
        "# SyntaxError: bytes can only contain ASCII literal characters\n"
      ],
      "metadata": {
        "id": "ZUWU-McKIEkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bytes are represented as an `int` sequence in Python, each byte is a number\n",
        "# between [0, 255] -> 2**8. Only 0-127 are printible (ASCII) characters, rest\n",
        "# will be represented as a hexadecimal string `\\xCC`. Note: Hexadecimal is\n",
        "# base-16 which is 2**4, which is half a byte. So all bytes beyond the printable\n",
        "# ASCII range will can be covered by the hexadecimal range.\n",
        "\n",
        "print([tokens[i+20] for i in range(10)])\n",
        "print(tokens[20:30])\n",
        "\n",
        "# tokens[i] is an integer, while tokens[0:1] is a single bytes object."
      ],
      "metadata": {
        "id": "EpMErpUDIGSW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}